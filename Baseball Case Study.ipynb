{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5812579",
   "metadata": {},
   "source": [
    "### Baseball Case project by Francis Afuwah.\n",
    "Batch: DS2312"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ee8bb8",
   "metadata": {},
   "source": [
    "### 1.0 Overview\n",
    "This document describes the general methodology that has been applied throughout the development of a machine-learning model whose main purpose is to predict Major League Baseball team wins using historical data. The model utilizes different team-performance features and applies a number of regression techniques to statistically predict the number of wins."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adff1bf8",
   "metadata": {},
   "source": [
    "### 1.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f869f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9a0010",
   "metadata": {},
   "source": [
    "### 1.2 Loading and Preprocessing Data\n",
    "1. Data source: CSV file containing the team performance statistics dataset.\n",
    "2. Exploring the data: Displaying the first few rows of the data and summarizing it allows us to know the types of data and their distribution.\n",
    "3. Rename Columns: Renaming columns to better understandable titles according to the descriptions of given features, makes the data handling procedures easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7160954",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the dataset \n",
    "data = pd.read_csv(r'\\Users\\Admin\\Desktop\\Flip Robo-Intern\\Datasets\\baseball.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dd1ad68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       1      2    3    4   5  6   7    8   9   10  11  12  13  14  15  16  \\\n",
      "0  0.271  0.328   74  161  22  6  12   58  49  133  23  17   1   1   0   0   \n",
      "1  0.264  0.318   24   48   7  0   1   22  15   18   0   7   0   0   0   0   \n",
      "2  0.251  0.338  101  141  35  3  32  105  71  104  34   6   0   0   1   0   \n",
      "3  0.224  0.274   28   94  21  1   1   44  27   54   2   7   1   1   0   0   \n",
      "4  0.206  0.262   14   51  18  1   1   28  17   26   0   3   1   1   0   0   \n",
      "\n",
      "   salary  \n",
      "0     109  \n",
      "1     160  \n",
      "2    2700  \n",
      "3     550  \n",
      "4     300  \n",
      "                1           2           3           4           5           6  \\\n",
      "count  337.000000  337.000000  337.000000  337.000000  337.000000  337.000000   \n",
      "mean     0.257825    0.323973   46.697329   92.833828   16.673591    2.338279   \n",
      "std      0.039546    0.047132   29.020166   51.896322   10.452001    2.543336   \n",
      "min      0.063000    0.063000    0.000000    1.000000    0.000000    0.000000   \n",
      "25%      0.238000    0.297000   22.000000   51.000000    9.000000    0.000000   \n",
      "50%      0.260000    0.323000   41.000000   91.000000   15.000000    2.000000   \n",
      "75%      0.281000    0.354000   69.000000  136.000000   23.000000    3.000000   \n",
      "max      0.457000    0.486000  133.000000  216.000000   49.000000   15.000000   \n",
      "\n",
      "                7           8           9          10          11          12  \\\n",
      "count  337.000000  337.000000  337.000000  337.000000  337.000000  337.000000   \n",
      "mean     9.097923   44.020772   35.017804   56.706231    8.246291    6.771513   \n",
      "std      9.289934   29.559406   24.842474   33.828784   11.664782    5.927490   \n",
      "min      0.000000    0.000000    0.000000    1.000000    0.000000    0.000000   \n",
      "25%      2.000000   21.000000   15.000000   31.000000    1.000000    3.000000   \n",
      "50%      6.000000   39.000000   30.000000   49.000000    4.000000    5.000000   \n",
      "75%     15.000000   66.000000   49.000000   78.000000   11.000000    9.000000   \n",
      "max     44.000000  133.000000  138.000000  175.000000   76.000000   31.000000   \n",
      "\n",
      "               13          14          15          16       salary  \n",
      "count  337.000000  337.000000  337.000000  337.000000   337.000000  \n",
      "mean     0.397626    0.115727    0.192878    0.029674  1248.528190  \n",
      "std      0.490135    0.320373    0.395145    0.169938  1240.013309  \n",
      "min      0.000000    0.000000    0.000000    0.000000   109.000000  \n",
      "25%      0.000000    0.000000    0.000000    0.000000   230.000000  \n",
      "50%      0.000000    0.000000    0.000000    0.000000   740.000000  \n",
      "75%      1.000000    0.000000    0.000000    0.000000  2150.000000  \n",
      "max      1.000000    1.000000    1.000000    1.000000  6100.000000  \n"
     ]
    }
   ],
   "source": [
    "# Displaying the first few rows and a summary description of the dataset\n",
    "print(data.head())\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60dd5a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the columns based on the provided feature descriptions\n",
    "column_names = [\n",
    "    \"W\", \"R\", \"AB\", \"H\", \"2B\", \"3B\", \"HR\", \"BB\", \"SO\", \"SB\",\n",
    "    \"RA\", \"ER\", \"ERA\", \"CG\", \"SHO\", \"SV\", \"E\"\n",
    "]\n",
    "data.columns = column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04415e1",
   "metadata": {},
   "source": [
    "### 2.0 Making data ready and data prep\n",
    "\n",
    "1. Feature Scaling: Excludes all features from the standard variable 'W' for wins.\n",
    "\n",
    "2. Adding New Features: Create two new features, Batting_Average and Slugging_Percentage, to give more insight regarding the team performance.\n",
    "3. Data Cleaning: It replaces infinite values or missing data with zeros so that it does not disrupt the model training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767b759a",
   "metadata": {},
   "source": [
    "### 2.1 Data Preprocessing and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd235de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the features\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(data.drop(['W'], axis=1))\n",
    "scaled_df = pd.DataFrame(scaled_features, columns=data.columns[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c7fde6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding new features\n",
    "singles = data['H'] - (data['2B'] + data['3B'] + data['HR'])\n",
    "scaled_df['Batting_Average'] = data['H'] / data['AB']\n",
    "scaled_df['Slugging_Percentage'] = (singles + 2 * data['2B'] + 3 * data['3B'] + 4 * data['HR']) / data['AB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7eccfd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling potential infinities and NaNs\n",
    "scaled_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "scaled_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdeb8449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_df, data['W'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87420d99",
   "metadata": {},
   "source": [
    "### 3.0 Training of Models and Their Evaluation\n",
    "1. Model Selection: These four models are Linear Regression, Decision Tree, Random Forest, and Gradient Boosting Regressor.\n",
    "2. Training: Scale the features and train the model.\n",
    "3. Evaluation: MAE and RMSE measures will be extracted for the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0140372c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(data.drop('W', axis=1))\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_scaled, data['W'], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7cc354b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression trained.\n",
      "Decision Tree trained.\n",
      "Random Forest trained.\n",
      "Gradient Boosting trained.\n"
     ]
    }
   ],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(random_state=42),\n",
    "    \"Random Forest\": RandomForestRegressor(random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "# Train models\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    print(f\"{name} trained.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1095848",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Performance: {'Train MAE': 0.008288968512317762, 'Test MAE': 0.011260315647597037, 'Train RMSE': 0.012830519742369706, 'Test RMSE': 0.017749565611179727}\n",
      "Decision Tree Performance: {'Train MAE': 0.0, 'Test MAE': 0.01802941176470588, 'Train RMSE': 0.0, 'Test RMSE': 0.02613258052136991}\n",
      "Random Forest Performance: {'Train MAE': 0.005121263940520431, 'Test MAE': 0.012863970588235303, 'Train RMSE': 0.007833426375043931, 'Test RMSE': 0.01941981004178012}\n",
      "Gradient Boosting Performance: {'Train MAE': 0.0026127517008521753, 'Test MAE': 0.009822843733609315, 'Train RMSE': 0.0033796668775065816, 'Test RMSE': 0.015700909520507907}\n"
     ]
    }
   ],
   "source": [
    "# Function to evaluate the models\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    train_preds = model.predict(X_train)\n",
    "    test_preds = model.predict(X_test)\n",
    "    metrics = {\n",
    "        \"Train MAE\": mean_absolute_error(y_train, train_preds),\n",
    "        \"Test MAE\": mean_absolute_error(y_test, test_preds),\n",
    "        \"Train RMSE\": np.sqrt(mean_squared_error(y_train, train_preds)),\n",
    "        \"Test RMSE\": np.sqrt(mean_squared_error(y_test, test_preds))\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "# Evaluate and print the performance of each model\n",
    "for name, model in models.items():\n",
    "    metrics = evaluate_model(model, X_train, y_train, X_test, y_test)\n",
    "    print(f\"{name} Performance: {metrics}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365a5b0e",
   "metadata": {},
   "source": [
    "### 4.0 Model Optimization\n",
    "Grid Search: Applied on Gradient Boosting Regressor to fine-tune hyperparameters such as n_estimators, learning_rate, and max_depth.\n",
    "Best Model Selection: What will be done here is to identify the best parameters and then retrain the model using those optimized settings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79244ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "Best Parameters: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# Grid search parameters\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'max_depth': [3, 5]\n",
    "}\n",
    "\n",
    "# Setup GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=GradientBoostingRegressor(random_state=42),\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           cv=3,\n",
    "                           verbose=1)\n",
    "\n",
    "# Perform grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Best model\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a54ff09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Performance: {'Train MAE': 0.0011308382493280045, 'Test MAE': 0.009198377723720612, 'Train RMSE': 0.0014578533927352218, 'Test RMSE': 0.01478032155621409}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the best model from grid search\n",
    "best_metrics = evaluate_model(best_model, X_train, y_train, X_test, y_test)\n",
    "print(\"Best Model Performance:\", best_metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cfe09c",
   "metadata": {},
   "source": [
    "### 5.0 Final Model Training and Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e737d768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 0.00021845790530508686\n"
     ]
    }
   ],
   "source": [
    "final_model = grid_search.best_estimator_\n",
    "y_pred = final_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Test MSE: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e07d413f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully to: C:\\Users\\Admin\\Desktop\\Flip Robo-Intern\\Datasets\\baseball_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# Specify the file name and path\n",
    "model_path = r'C:\\Users\\Admin\\Desktop\\Flip Robo-Intern\\Datasets\\baseball_model.pkl'\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(final_model, model_path)\n",
    "print(\"Model saved successfully to:\", model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a963b02",
   "metadata": {},
   "source": [
    "### 6.0 Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e3a593f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of predicted wins (W): [0.23417135 0.22363396 0.2737471  0.29279285 0.27928345 0.26146156\n",
      " 0.291897   0.25559584 0.20575369 0.24140603 0.29934622 0.26343065\n",
      " 0.12867751 0.27874131 0.21600342 0.25200186 0.2715085  0.29788143\n",
      " 0.29902979 0.24770042 0.24437874 0.26056935 0.21040182 0.24510116\n",
      " 0.30206567 0.24143723 0.3133333  0.27161034 0.24715905 0.23518055\n",
      " 0.23765968 0.23343751 0.23042589 0.26096947 0.25093978 0.2425882\n",
      " 0.26047312 0.2333012  0.2279649  0.29300551 0.21529046 0.24295576\n",
      " 0.25222092 0.26861074 0.26250756 0.24627604 0.25956634 0.28155989\n",
      " 0.25768772 0.24028341 0.24860997 0.24196058 0.28495197 0.24673924\n",
      " 0.29764867 0.28892332 0.3024204  0.21316357 0.26055049 0.12193192\n",
      " 0.26044577 0.27409992 0.27481712 0.25015169 0.31637968 0.26163577\n",
      " 0.21465798 0.24649704]\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "final_model = joblib.load(r'C:\\Users\\Admin\\Desktop\\Flip Robo-Intern\\Datasets\\baseball_model.pkl')\n",
    "\n",
    "# Assuming you have the test features loaded in X_test (you need to preprocess it as per your model's requirements)\n",
    "y_pred = final_model.predict(X_test)\n",
    "\n",
    "# Output the predicted wins\n",
    "print(\"Number of predicted wins (W):\", y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2c0e9d",
   "metadata": {},
   "source": [
    "### 7.0 Conclusion:\n",
    "The study on the development of Major League Baseball wins is quite deep and insightful in coming up with the predictive model. Due to the application of several statistical data points, this project was able to provide a frame capable of predicting team performance with a high accuracy level. The development of advanced regression models namely linear regression, decision tree, random forest, and gradient boosting enabled the results to be carefully analyzed within the context of the most dominant features leading a team toward success.\n",
    "\n",
    "These preprocessing steps, scaling and feature engineering, did much toward increasing the performance of the model. An overall improved analytical view was taken by adding derived metrics such as batting average and slugging percentage, and this increased the predictivity of the model. This means that the richness of a data set can heavily increase with thoughtful feature engineering, such that it further results in more precise predictions.\n",
    "\n",
    "Application of GridSearchCV for model finetuning of Gradient Boosting Regressor has shown that hyperparameter optimization is too crucial in securing optimal model performance. This helps in finding the best set of model parameters, which probably has practical impact on predictive accuracy due to machine learning optimizations.\n",
    "\n",
    "Operationally, the final model will be able to predict not only wins but also be used as a strategic asset for management and planning around the team. This will be in a position to make strategic decisions on the next player to trade, where to focus on training, or game strategies and, hence, improve the competitive edge of the team.\n",
    "\n",
    "The project has also pointed out future improvements and iterations to the work, such as extension of the feature set, the use of more complex modeling techniques, and real-time data updates for continuous model learning. These improvements will thus enhance the effectiveness and flexibility of this model under changing dynamics in sports analytics.\n",
    "\n",
    "In conclusion, such a study lays the groundwork for strong predictive modeling in sports and shows the tremendous potential for fusion between data science and sports management. The set of paradigms that are set by such a study is sure to grow toward being central in strategic sports decision-making as the field of sports analytics grows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fff41c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
